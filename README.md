# Linear Regression from Scratch using NumPy

## Overview
This project implements a Linear Regression model from scratch using only NumPy without relying on machine learning libraries such as Scikit-learn. The model is trained using Gradient Descent optimization to learn the relationship between input features and target values.

This project demonstrates a strong understanding of the mathematical foundations behind machine learning algorithms and how optimization techniques are applied to train predictive models.

---

## Problem Statement
Linear Regression is one of the most fundamental supervised learning algorithms used for predictive analysis. The objective is to model the relationship between an independent variable (X) and a dependent variable (y) by fitting a linear equation to observed data.

---

## Methodology
The following steps were implemented manually:

- Synthetic dataset generation
- Feature matrix preparation
- Bias term addition
- Cost function (Mean Squared Error)
- Gradient Descent optimization
- Parameter (theta) updates
- Model prediction
- Cost convergence visualization
- Regression line plotting

---

## Tools & Technologies
- Python
- NumPy
- Pandas
- Matplotlib

---

## Key Concepts Covered
- Supervised Learning
- Linear Regression
- Gradient Descent
- Cost Function Optimization
- Model Training from Scratch
- Numerical Optimization

---
## Model Training
The model parameters were initialized randomly and updated iteratively using Gradient Descent to minimize the Mean Squared Error cost function.

---

## Evaluation
The convergence of the cost function over multiple iterations was plotted to verify the effectiveness of the optimization process.

---

## Results
The trained model successfully learned the linear relationship between input features and output values and demonstrated consistent reduction in cost during training.

---


1. Clone the repository:
