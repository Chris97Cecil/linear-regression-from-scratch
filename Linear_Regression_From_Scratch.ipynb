{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e11af1b",
   "metadata": {},
   "source": [
    "# Linear Regression from Scratch (Using Only NumPy)\n",
    "A clean implementation of Linear Regression using Gradient Descent without ML libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12ebc8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6154fa",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset\n",
    "Synthetic dataset for regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cc9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9408936",
   "metadata": {},
   "source": [
    "## 3. Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot data points\n",
    "plt.scatter(X, y)\n",
    "plt.title(\"Synthetic Data for Linear Regression\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84edd7",
   "metadata": {},
   "source": [
    "## 4. Add Bias Term\n",
    "Add column of 1s for intercept (theta0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1cd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add bias (intercept term)\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1dadea",
   "metadata": {},
   "source": [
    "## 5. Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b47753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random initialization of weights\n",
    "theta = np.random.randn(2,1)\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "m = len(X_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78645e60",
   "metadata": {},
   "source": [
    "## 6. Cost Function (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91753389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mean Squared Error function\n",
    "def compute_cost(X, y, theta):\n",
    "    predictions = X.dot(theta)\n",
    "    error = predictions - y\n",
    "    return (1/(2*m)) * np.sum(error**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a61ff1",
   "metadata": {},
   "source": [
    "## 7. Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8473aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform gradient descent\n",
    "cost_history = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    gradients = (1/m) * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - learning_rate * gradients\n",
    "    cost_history.append(compute_cost(X_b, y, theta))\n",
    "\n",
    "print(\"Optimized Theta:\\n\", theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18a98c",
   "metadata": {},
   "source": [
    "## 8. Plot Cost Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot cost vs iterations\n",
    "plt.plot(cost_history)\n",
    "plt.title(\"Cost Function Reduction\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2dbc26",
   "metadata": {},
   "source": [
    "## 9. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497779db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict values using trained model\n",
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new]\n",
    "y_predict = X_new_b.dot(theta)\n",
    "\n",
    "print(\"Predictions:\\n\", y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434df649",
   "metadata": {},
   "source": [
    "## 10. Plot Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot regression line\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X_new, y_predict, 'r-')\n",
    "plt.title(\"Linear Regression Fit\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
